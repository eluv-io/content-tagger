
from podman import PodmanClient
from src.common.logging import logger
import json
import os
from copy import copy
import socket
from urllib.parse import unquote
import time
from functools import lru_cache

from common_ml.utils.files import get_file_type
from common_ml.video_processing import get_fps

from src.tag_containers.model import FrameTag
from src.common.errors import BadRequestError
from src.tags.tagstore.model import Tag
from src.tag_containers.model import *

logger = logger.bind(name="TagContainer")

class TagContainer:

    def __init__(
        self,
        pclient: PodmanClient,
        cfg: ContainerSpec
    ):
        self.cfg = cfg

        if isinstance(self.cfg.media_input, str):
            # single directory
            if not os.path.exists(self.cfg.media_input):
                raise FileNotFoundError(f"Directory {self.cfg.media_input} not found")
            elif not os.path.isdir(self.cfg.media_input):
                raise NotADirectoryError(f"{self.cfg.media_input} is not a directory")
            self.media_files = [os.path.join(self.cfg.media_input, f) for f in os.listdir(self.cfg.media_input)]
        else:
            self.media_files = self.cfg.media_input

        self.media_dir = self._find_common_root(self.media_files)

        max_depth = self._calculate_max_depth(self.media_files, self.media_dir)
        
        if max_depth > 3:
            raise BadRequestError(f"Files are too deeply nested ({max_depth} levels below common root). Maximum allowed depth is 3.\n {self.media_files}")

        file_types = [get_file_type(f) for f in self.media_files]
        if len(set(file_types)) > 1:
            raise BadRequestError(f"All files must be of the same type: {self.media_files}")
        if len(file_types) == 0:
            raise ValueError("No files provided")
        self.file_type = file_types[0]
        if self.file_type not in ["video", "audio", "image"]:
            raise BadRequestError(f"Unsupported file type: {self.media_files[0]}")
        # check that no file has the same basename
        self.basename_to_source = {os.path.basename(f): f for f in self.media_files}
        if len(self.basename_to_source) != len(self.media_files):
            raise BadRequestError("Files must have unique basenames")
        self.pclient = pclient
        self.container = None

    def start(
        self, 
        gpuidx: int | None,
        # only used for live containers
        # TODO: ugly
        stdin_open: bool = False
    ) -> None:
        os.makedirs(self.cfg.tags_dir, exist_ok=True)
        
        volumes = [
            {
                "source": self.cfg.tags_dir,
                # convention for containers to store tags in /elv/tags
                "target": "/elv/tags",
                "type": "bind",
            },
            {
                "source": self.cfg.cache_dir,
                # convention for python modules to store cache in /root/.cache
                "target": "/root/.cache",
                "type": "bind",
                "read_only": False
            },
            {
                "source": self.media_dir,
                "target": "/elv/media",
                "type": "bind",
                "read_only": True
            }
        ]

        cmd = self._get_args(self._get_relative_paths(self.media_files))

        kwargs = {
            "image": self.cfg.model_config.image,
            "command": cmd,
            "mounts": volumes,
            "remove": True,
            "network_mode": "host",
            "log_config": {
                "Type": "k8s-file",
                "Config": {
                    "path": self.cfg.logs_path
                }
            }
        }

        if stdin_open:
            kwargs["stdin_open"] = True
            kwargs["tty"] = False

        if gpuidx is not None:
            kwargs["devices"] = [f"nvidia.com/gpu={gpuidx}"]

        container = self.pclient.containers.create(**kwargs)
        container.start()
        self.container = container

    def stop(self) -> None:
        if not self.container:
            return
        if self.container.status == "running":
            self.container.stop(timeout=5)
        if self.is_running():
            logger.warning("Container did not stop in time, killing it", extra={"container_id": self.container.id, "handle": self.name()})
            self.container.kill()

    def is_running(self) -> bool:
        if self.container is None:
            return False
        self.container.reload()
        return self.container.status == "running"

    def exit_code(self) -> int | None:
        """Returns exit code if available, else None"""
        if self.container is None:
            return None
        self.container.reload()
        if self.container.status == "exited":
            return self.container.attrs["State"]["ExitCode"]
        return None

    def tags(self) -> list[ModelOutput]:
        """
        Get output tags generated by the running container so far.

        NOTE: this list should be append only and no previous outputs should be modified.
        This responsibility is on the container implementation.
        """
        if not os.path.exists(self.cfg.tags_dir):
            # hasn't started
            return []

        tag_files = []
        for fpath in os.listdir(self.cfg.tags_dir):
            tag_files.append(os.path.join(self.cfg.tags_dir, fpath))

        return self._files_to_tags(tag_files)
    
    def name(self) -> str:
        """A human friendly name for the container, useful for logging"""
        return f"{self.cfg.id}_{self.cfg.model_config.image}"

    def required_resources(self) -> SystemResources:
        """Returns the system resources required by this container to run."""
        return copy(self.cfg.model_config.resources)

    def send_eof(self) -> None:
        logger.info(f"Standard container received EOF (noop), no more media will be sent.", extra={"handle": self.name()})
        pass
    
    def _get_relative_paths(self, media_files: list[str]) -> list[str]:
        # Calculate paths from perspective of the container working directory "/elv"
        relative_paths = []
        for f in media_files:
            if not os.path.exists(f):
                raise FileNotFoundError(f"File {f} not found")
            elif not os.path.isfile(f):
                raise IsADirectoryError(f"{f} is a directory")
            elif not os.path.isabs(f):
                raise ValueError(f"{f} must be an absolute path")
            elif not f.startswith(self.media_dir):
                raise ValueError(f"{f} is not in media directory {self.media_dir}")
            
            rel_path = os.path.relpath(f, self.media_dir)
            relative_paths.append(f"media/{rel_path}")
        return relative_paths
    
    def _get_args(self, media_files: list[str]) -> list[str]:
        """Get command line arguments for the container"""
        cmd = media_files + ["--config", f"{json.dumps(self.cfg.run_config)}"]
        return cmd
    
    def _files_to_tags(self, tagged_files: list[str]) -> list[ModelOutput]:

        if self.file_type == "image":
            return self._load_image_tags(tagged_files)
        elif self.file_type == "video" or self.file_type == "audio":
            return self._load_video_tags(tagged_files)
        else:
            raise ValueError(f"Unsupported file type: {self.file_type}")

    def _load_image_tags(self, tagged_files: list[str]) -> list[ModelOutput]:
        outputs = []
        for tagged_file in tagged_files:
            source = self._source_from_tag_file(tagged_file)
            image_tags = []
            try:
                with open(tagged_file, 'r') as f:
                    image_tags = json.load(f)
            except Exception as e:
                logger.error(f"Error loading image tags from {tagged_file}: {e}")
                continue
            outputs.append(self._output_from_image_tags(source, image_tags))
        return outputs

    def _output_from_image_tags(self, source_image: str, image_tags: list[dict]) -> ModelOutput:
        tags = []
        for image_tag_data in image_tags:
            tags.append(Tag(
                start_time=0,
                end_time=0,
                text=image_tag_data.get("text", ""),
                additional_info={
                    "confidence": image_tag_data.get("confidence", 0.0),
                    "box": image_tag_data.get("box", [])
                },
                frame_tags={},
                source="",
                batch_id=""
            ))

        return ModelOutput(
            source_media=source_image,
            tags=tags
        )
        
    def _load_video_tags(self, tagged_files: list[str]) -> list[ModelOutput]:
        
        source_to_tagfiles = {}

        for tagged_file in tagged_files:
            source_media = self._source_from_tag_file(tagged_file)
            if source_media not in source_to_tagfiles:
                source_to_tagfiles[source_media] = []
            source_to_tagfiles[source_media].append(tagged_file)

        outputs = []
        for source_media, tag_files in source_to_tagfiles.items():
            model_out = self._output_from_tags(source_media, tag_files)
            if model_out:
                outputs.append(model_out)

        return outputs
    
    @lru_cache(maxsize=1024)
    def _get_fps(self, video_file: str) -> float:
        return get_fps(video_file)

    def _output_from_tags(self, source_video: str, tag_files: list[str]) -> ModelOutput | None:
        ftype = get_file_type(source_video)
    
        vid_tags = None
        frame_tags = None

        for tag_file in tag_files:
            try:
                if tag_file.endswith("_tags.json"):
                    with open(tag_file, 'r') as f:
                        vid_tags = json.load(f)
                elif tag_file.endswith("_frametags.json"):
                    with open(tag_file, 'r') as f:
                        frame_tags = json.load(f)
            except Exception as e:
                logger.error(f"Error loading tags from {tag_file}: {e}")
                continue
        
        if vid_tags is None:
            return None
        
        if frame_tags and ftype == "video":
            fps = self._get_fps(source_video)
        else:
            fps = None

        # Convert video tags to Tag objects with enhanced additional_info
        tags = []

        for video_tag_data in vid_tags:
            # Create base Tag object from video tag
            tag = Tag(
                start_time=video_tag_data.get("start_time", 0),
                end_time=video_tag_data.get("end_time", 0),
                text=video_tag_data.get("text", ""),
                additional_info={},
                frame_tags={},
                source="",
                batch_id=""
            )

            if frame_tags:
                if ftype != "video":
                    raise ValueError("Frame tags can only be associated with video files")
                # Find overlapping frame tags with matching text
                assert fps is not None
                overlapping_frame_tags = self._find_overlapping_frame_tags(
                    tag, frame_tags, fps
                )
                
                # Enhance additional_info with frame tag data
                if overlapping_frame_tags:
                    frame_info = {}
                    for ftag in overlapping_frame_tags:
                        frame_info[ftag.frame_idx] = {
                            "confidence": ftag.confidence,
                            "box": ftag.box
                        }
                    tag.frame_tags = frame_info

            tags.append(tag)

        return ModelOutput(
            source_media=source_video,
            tags=tags
        )

    def _source_from_tag_file(self, tagfile: str) -> str:
        """
        Extract the source from the tag file name.
        """
        basename = os.path.basename(tagfile)
        # remove _tags, _frametags, or _imagetags suffix
        path_parts = basename.split("_")
        if len(path_parts) < 2:
            raise ValueError(f"Invalid tag file name: {basename}")
        suffix = path_parts[-1]
        if suffix not in ["tags.json", "frametags.json", "imagetags.json"]:
            raise ValueError(f"Invalid tag file suffix: {suffix}")
        original_filebase = "_".join(path_parts[:-1])

        return self.basename_to_source[original_filebase]

    def _find_overlapping_frame_tags(
        self, 
        video_tag: Tag, 
        frame_tags_data: dict, 
        fps: float
    ) -> list[FrameTag]:
        overlapping_tags = []
        for fidx, ftags in frame_tags_data.items():
            frame_time = (int(fidx) / fps) * 1000
            if video_tag.start_time <= frame_time < video_tag.end_time:
                for ftag in ftags:
                    if ftag.get("text", "") == video_tag.text:
                        overlapping_tags.append(FrameTag(
                            frame_idx=fidx,
                            confidence=ftag.get("confidence", 0.0),
                            box=ftag.get("box", None),
                            text=ftag.get("text", "")
                        ))
        return overlapping_tags

    def _find_common_root(self, filepaths: list[str]) -> str:
        """Find the common root directory for all files"""
        if not filepaths:
            raise ValueError("No files provided")
        
        # Get absolute paths
        abs_paths = [os.path.abspath(f) for f in filepaths]
        
        # Find common prefix
        common_prefix = os.path.commonpath(abs_paths)
        
        # If common prefix is a file (only one file), use its directory
        if os.path.isfile(common_prefix):
            common_prefix = os.path.dirname(common_prefix)
        
        return common_prefix

    def _calculate_max_depth(self, filepaths: list[str], root: str) -> int:
        """Calculate maximum depth of files relative to root directory"""
        max_depth = 0
        
        for filepath in filepaths:
            rel_path = os.path.relpath(filepath, root)
            # Count directory separators to determine depth
            depth = rel_path.count(os.sep)
            max_depth = max(max_depth, depth)
        
        return max_depth
    
class LiveTagContainer(TagContainer):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.stdin_socket = None
        self.eof = False

    def add_media(self, new_media: list[str]) -> None:
        if not self.is_running():
            logger.warning("Container is not running, cannot add media", extra={"handle": self.name()})
            return
        
        if len(new_media) == 0:
            return
        
        # add to base_name_to_source map
        for f in new_media:
            self.basename_to_source[os.path.basename(f)] = f

        assert self.stdin_socket is not None
        
        media_files = self._get_relative_paths(new_media)

        logger.info(f"Adding {len(media_files)} media files to live container: {media_files[:2]}...]")

        msg = "\n".join(media_files) + "\n"
        self.stdin_socket.sendall(msg.encode())

    # TODO: need to verify that tagger handles the exceptions nicely
    def start(self, gpuidx: int | None, stdin_open: bool=True) -> None:
        if self.eof:
            # TODO: not optimal
            raise RuntimeError("Live container has already received EOF, cannot start again.")
        super().start(gpuidx, True)
        timeout = 10
        start = time.time()
        has_started = False
        while time.time() - start < timeout:
            if self.is_running():
                has_started = True
                break
            time.sleep(0.1)
        if not has_started:
            raise RuntimeError(f"Container did not start in time: {self.name()}")
        self.stdin_socket = self._open_container_stdin(self.container)
        # add initial media files to stdin
        if self.media_files:
            self.add_media(self.media_files)

    def send_eof(self) -> None:
        self.eof = True
        if self.stdin_socket:
            try:
                try:
                    self.stdin_socket.shutdown(socket.SHUT_WR)
                except OSError:
                    pass
                finally:
                    self.stdin_socket.close()
            except Exception as e:
                logger.opt(exception=e).error("Error closing stdin socket", extra={"handle": self.name()})
        else:
            logger.warning("No stdin socket to close", extra={"handle": self.name()})

    def stop(self) -> None:
        self.send_eof()
        super().stop()

    def _get_args(self, media_files: list[str]) -> list[str]:
        args = ["--config", f"{json.dumps(self.cfg.run_config)}"]
        args.append("--live")
        return args
    
    def _open_container_stdin(self, container):    
        ## assume podman is on the same machine via unix socket
        consocket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
        consocket.connect(unquote(container.client.base_url.netloc))

        ## we have to do this manually, because once the podman socket server accepts the POST
        ## it then converts the socket into a "raw" socket for writing directly to the container's stdin
        msg = f"POST /v5.4.0/libpod/containers/{container.id}/attach?stdin=1&stdout=0&stderr=0 HTTP/1.0\r\n\r\n".encode()
        consocket.sendall(msg)

        ## response looks like this: 'HTTP/1.1 200 OK\r\nContent-Type: application/vnd.docker.raw-stream\r\n\r\n'
        response = consocket.recv(4096)
        
        logger.debug(f"socket response: {response}")
        
        ## make sure we successfully opened the connection
        ## be slightly flexible but otherwise pretty strict
        if response[0:15] != bytes("HTTP/1.1 200 OK", "utf-8") and response[0:15] != bytes("HTTP/1.0 200 OK", "utf-8"):
            raise Exception(f"Did not successfully open stdin for container: {response}")
        
        return consocket